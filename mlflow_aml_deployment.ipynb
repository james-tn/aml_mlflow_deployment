{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "# mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'mlflow-aml-deployment'\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlflow.models.model.Model at 0x22f1ad67e20>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow.pyfunc\n",
    "from sys import version_info\n",
    "\n",
    "from pyimagesearch import config\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.models import load_model\n",
    "import pip\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "\n",
    "# Construct and save the model\n",
    "PYTHON_VERSION = \"{major}.{minor}.{micro}\".format(major=version_info.major,\n",
    "                                                  minor=version_info.minor,\n",
    "                                                  micro=version_info.micro)\n",
    "# artifacts = {\n",
    "#     \"model_path\": \"output\"\n",
    "# }\n",
    "\n",
    "conda_env = {\n",
    "    'channels': ['defaults'],\n",
    "    'dependencies': [\n",
    "      'python={}'.format(PYTHON_VERSION),\n",
    "      'pip',\n",
    "      {\n",
    "        'pip': [\n",
    "          'mlflow',\n",
    "            'imutils',\n",
    "            'opencv-python-headless',\n",
    "            'pillow',\n",
    "            'azureml-mlflow',\n",
    "          'tensorflow=={}'.format(tf.__version__),\n",
    "          'scikit-learn=={}'.format(sklearn.__version__),\n",
    "        ],\n",
    "      },\n",
    "    ],\n",
    "    'name': 'tf_env'\n",
    "}\n",
    "\n",
    "\n",
    "model_path = \"model\"\n",
    "# object_detection = Object_Detection()\n",
    "mlflow.pyfunc.save_model(path=model_path, data_path ='output',loader_module ='pyimagesearch.model_loader', code_path=['pyimagesearch'], conda_env=conda_env)\n",
    "\n",
    "# Load the model in `python_function` format\n",
    "# loaded_model = mlflow.pyfunc.load_model(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the deployed service\n",
    "#preparing data\n",
    "\n",
    "from io import BytesIO\n",
    "import json\n",
    "import base64\n",
    "ENCODING = 'utf-8'\n",
    "test_image_paths =['dataset/images/airplane/image_0001.jpg','dataset/images/airplane/image_0002.jpg']\n",
    "base64_string_list=[]\n",
    "for test_image_path in test_image_paths:\n",
    "    with open(test_image_path,\"rb\") as img:\n",
    "        image_bytes = BytesIO(img.read())\n",
    "\n",
    "    encoded_image =base64.b64encode(image_bytes.getvalue())\n",
    "    base64_string = encoded_image.decode(ENCODING)\n",
    "    base64_string= \"b'{0}'\".format(base64_string)\n",
    "    base64_string_list.append(base64_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.pyfunc.scoring_server import parse_json_input, _get_jsonable_obj\n",
    "\n",
    "import json\n",
    "# data = json.loads(body)['data']\n",
    "out = parse_json_input(json_input=body, orient=\"split\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import mlflow\n",
    "model_path = \"model\"\n",
    "loaded_model = mlflow.pyfunc.load_model(model_path)\n",
    "\n",
    "pred_output = loaded_model.predict(out)\n",
    "print(pred_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "\n",
    "# Set the model path to the model folder created by your run\n",
    "\n",
    "# Configure \n",
    "aci_config = AciWebservice.deploy_configuration(cpu_cores=1, \n",
    "                                                memory_gb=4, \n",
    "                                                tags={'method' : 'keras/tf'}, \n",
    "                                                description='aml-mlflow model',\n",
    "                                                location='westus2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model object_detection_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021/01/19 10:49:34 INFO mlflow.azureml: Registered an Azure Model with name: `object_detection_model` and version: `19`\n",
      "2021/01/19 10:49:37 INFO mlflow.azureml: Deploying an Azure Webservice with name: `aml-mlflow-test-v2`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running...........................................\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "SucceededACI service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "import mlflow.azureml\n",
    "(webservice,model) = mlflow.azureml.deploy( model_uri=model_path,\n",
    "                      workspace=ws,\n",
    "                      model_name='object_detection_model', \n",
    "                      service_name='aml-mlflow-test-v2', \n",
    "                      deployment_config=aci_config, \n",
    "                      tags=None, mlflow_home=None, synchronous=True)\n",
    "\n",
    "webservice.wait_for_deployment(show_output=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1248638927936554, 0.1821192502975464, 0.8843519687652588, 0.834100604057312, 'airplane'], [0.14209172129631042, 0.1815202832221985, 0.8583660125732422, 0.8296916484832764, 'airplane']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calling webservice object via AML API\n",
    "image_request = {\"data\": base64_string_list}\n",
    "# payload.append(image_request)\n",
    "\n",
    "body = json.dumps(image_request)\n",
    "response = webservice.run(body)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1248638927936554, 0.1821192502975464, 0.8843519687652588, 0.834100604057312, \"airplane\"], [0.14209172129631042, 0.1815202832221985, 0.8583660125732422, 0.8296916484832764, \"airplane\"]]\n"
     ]
    }
   ],
   "source": [
    "#another way to call http request directly \n",
    "import requests\n",
    "\n",
    "response = requests.post(url=webservice.scoring_uri, data=body,headers={\"Content-type\": \"application/json\"})\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize result\n",
    "import imutils\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "import ast\n",
    "pred_results = ast.literal_eval(response.text)\n",
    "for pred_result, imagePath in zip( pred_results,test_image_paths):\n",
    "\t# load the input image (in Keras format) from disk and preprocess\n",
    "\t# it, scaling the pixel intensities to the range [0, 1]\n",
    "\n",
    "\tstartX, startY, endX, endY,label = pred_result[0],pred_result[1],pred_result[2],pred_result[3],pred_result[4]\n",
    "\n",
    "\t# determine the class label with the largest predicted\n",
    "\t# probability\n",
    "\n",
    "\t# load the input image (in OpenCV format), resize it such that it\n",
    "\t# fits on our screen, and grab its dimensions\n",
    "\timage = cv2.imread(imagePath)\n",
    "\timage = imutils.resize(image, width=600)\n",
    "\t(h, w) = image.shape[:2]\n",
    "\n",
    "\t# scale the predicted bounding box coordinates based on the image\n",
    "\t# dimensions\n",
    "\tstartX = int(startX * w)\n",
    "\tstartY = int(startY * h)\n",
    "\tendX = int(endX * w)\n",
    "\tendY = int(endY * h)\n",
    "\n",
    "\t# draw the predicted bounding box and class label on the image\n",
    "\ty = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "\tcv2.putText(image, label, (startX, y), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "\t\t0.65, (0, 255, 0), 2)\n",
    "\tcv2.rectangle(image, (startX, startY), (endX, endY),\n",
    "\t\t(0, 255, 0), 2)\n",
    "\n",
    "\t# show the output image\n",
    "\tcv2.imshow(\"Output\", image)\n",
    "\tcv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
